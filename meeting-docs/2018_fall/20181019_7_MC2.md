# Friday, Oct 26 2018

## Recap of meeting 7 this semester!
- Monte Carlo methods can be used to evaluate integrals. 
- However some integrals may have divergences (go to infinity) in the interval of interest. This causes the estimates of the integral to have large variances.
- Importance sampling is a way to deal with functions that diverge by factoring that function into two parts and treating one of the parts as a probability density function and drawing our samples following that density (see the [notebook presented](https://github.com/prickly-pythons/prickly-pythons/blob/master/code_from_meetings/Monte%20Carlo/MC%20-%20Importance%20Sampling.ipynb) for more details.)
- So rather than sampling a difficult function uniformly, we now sample a better-behaved function non-uniformly. The result is the same.
- The way samples can be drawn non-uniformly following a specified distribution is via the [inverse transform method](https://en.wikipedia.org/wiki/Inverse_transform_sampling).
- Use `np.var(x, ddof=1)` to calculate the unbiased estimator of the population variance. 
`np.var(x, ddof=1)` is equivalent to `np.var(x) * (len(x)/(len(x)-1))`.


# More info:
The Jupyter notebook presented is [here](https://github.com/prickly-pythons/prickly-pythons/blob/master/code_from_meetings/Monte%20Carlo/MC%20-%20Importance%20Sampling.ipynb
).
<br>
Numpy variance documentation: https://docs.scipy.org/doc/numpy/reference/generated/numpy.var.html
