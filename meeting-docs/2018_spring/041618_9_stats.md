# Monday, Apr 16 2018

## Recap of our 10th meeting this semester! 
### Topic: Statistics

0. Coconut buns from [Happy Buns](http://goodfoodfinderaz.com/find-good-food/happy-buns-asian-bakery/), chocolates, lollies, pineapple pastry and coffee!
1. Jay gave an introductory review on Bayesian methods and Bayes' formula, covering topics ranging from likelihoods, overfitting, and evidence, to scale-invariant priors. 
2. [MultiNest](https://arxiv.org/abs/0809.3437) is a Bayesian parameter inference program that has a Python wrapper called pyMultiNest. Given a model and some data, the program tries to estimate a probability density function for the values of the parameters of the model from those data. Jay showed an example of how the parameters of a straight line can be estimated, along with their errors, by treating the noisy data in such a Bayesian approach. See his [notebook](https://github.com/prickly-pythons/prickly-pythons/blob/master/code_from_meetings/statistics/pyMultiNest_example.ipynb) for the details.
3. We then talked a bit about the [wisdom of the crowd](https://en.wikipedia.org/wiki/Wisdom_of_the_crowd) where, sometimes, the collective input is better than that from a few.
4. Finally we spontaneously broke into discussions of some interesting statistical ideas like biases and predicting the [end of our species](https://en.wikipedia.org/wiki/Doomsday_argument). 

Please visit our [homepage](http://prickly-pythons.github.io) where you can find topics for future meetings and links to the codes presented.
